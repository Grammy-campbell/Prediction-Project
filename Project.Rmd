---
output:
  html_document: default
  word_document: default
  pdf_document: default
---

#Using Accelerometer Data to Predict Activity
Author: L.K. Campbell

##Executive Summary:
The goal of this project was to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the 'classe' that they were in at the time the data was collected.  There were five different classes being studied: 

 A = sitting-down
 
 B = standing-up
 
 C = standing
 
 D = walking
 
 E = sitting

Five different models were attempted, but only three, decision trees, linear discriminate analysis, and quadratic discriminate analysis, yielded workable models. Of these, the quadratic discriminate model was clearly the superior predictor having an out of sample error rate of only 9% with a 95% confidence interval of (8%, 10%).

All analysis was done using the R programming language (version 3.4.4).

##Data Processing and Exploration
```{r,echo=FALSE,results='hide',message=FALSE}
## Load the required libraries
library(ggplot2)
library(caret)
## To get a better Tree plot
library(rattle)
## To assess multivariate normality
library(MVN)

## Load and process the data
## Read in the data
training = read.csv("pml-training.csv", header=TRUE)
quizDat = read.csv("pml-testing.csv", header=TRUE)
head(training)

summary(training)
## How many records
length(training$classe)

## How many columns
length(training[1,])

dim(quizDat)

## Subset by removing those variables for which there is very little data
## Also remove the row numbers and the time stamps
sub_train = training[,-c(1,3:5,12:36,50:59,69:83,87:101,103:112,125:139,141:150)]

summary(sub_train)

## Preprocess the quiz data in the same manner
sub_quiz = quizDat[,-c(1,3:5,12:36,50:59,69:83,87:101,103:112,125:139,141:150)]

## Create two subsets
set.seed=(2468)

## inTrain becomes an indicator.
inTrain = createDataPartition(y=sub_train$classe, p=0.75, list=FALSE)
training = sub_train[inTrain,]
testing = sub_train[-inTrain,]
dim(training)
dim(testing)

summary(training[,3:55])


```
The original dataset contained 19,622 records pertaining to individual tests, and there were 160 columns. However, many of the columns had a large number of missing values, so these were removed from the data. The final dataset contained 56 columns. It was divided into a training dataset (75%) and a testing dataset (25%). Additionally, there was a quiz dataset containing 20 records.


```{r,echo=FALSE,message=FALSE,results='hide'}

## Try reducing dimensionality using Principal Components
## Set a threshold of capturing 80% of variability.
preProc = preProcess(training[,3:55],method="pca",thresh = 0.8)
preProc

## Build a dataset that contains these PCs
trainPC = data.frame(cbind(training$classe, training$user_name, training$new_window,
	predict(preProc,training[,3:55])))

colnames(trainPC)[1] <- "classe"
colnames(trainPC)[2] <- "user_name"
colnames(trainPC)[3] <- "new_window"


## Build a dataset that contains these PCs
testPC = data.frame(cbind(testing$classe, testing$user_name, testing$new_window,
	predict(preProc,testing[,3:55])))

colnames(testPC)[1] <- "classe"
colnames(testPC)[2] <- "user_name"
colnames(testPC)[3] <- "new_window"



```
Dues to limitations placed on the length of this document, a detailed summary of the variables is not presented here.

Principal component analysis was used in data exploration. PC variables that explained 80% of the variation in the data were created. It took 14 variables to do this. The first two are plotted in Figure 1a and 1b. The color coding is used to determine if the data readily explains 'classe' and/or 'user' respectively.

```{r,echo=FALSE}
qplot(trainPC$PC1, trainPC$PC2, colour=trainPC$classe, 
	main="Figure 1a: PCs to Explain Classe", xlab="PC1", ylab="PC2", 
	data=trainPC)

## Explore whether or not the PCs explain user:
qplot(trainPC$PC1, trainPC$PC2, colour=trainPC$user_name,
	main="Figure 1b: PCs to Explain User", xlab="PC1", ylab="PC2", 
	data=trainPC)

```

These plots suggest that most of the variation in the data stems from differences in the users who were tested. The differences in classe appear to be much more subtle.


## Locating an optimal prediction model:
The dependent variable being predicted is categorical. This drove the choice of models. Six different models were tested. These included a decision tree, random forests, gradient boosting, linear discriminate analysis, quadratic discriminate analysis, and a stacking method to combine the most accurate of the individual models.

Unfortunately, both the random forests procedure and the gradient boosting procedure encountered computational problems and did not yield workable models.

All of the models were built using the 'train' function withing R's 'caret' package.

## Decision Tree
```{R,results='hide',echo=FALSE }
## Consider a tree

## Build our tree
modFit = train(classe~., method="rpart", data=training)
```

```{R,echo=FALSE}
par(mfrow=c(1,1))
## Create a plot of the result (Dendrogram)
## Get a prettier plot using the rattle packag
print("Figure 2: Decision Tree")
fancyRpartPlot(modFit$finalModel)
```
The decision tree model was rejected because: 1) It failed to predict any instances of classe = D, and 2) it had a prediction accuracy of only about 50% when applied to a data set other than the one used to develop the tree (i.e. out of sample error).

## Linear and Quadratic Discriminant Analysis
Exploration of the data suggested that these models would not be appropriate because they both assume that the predictor models are drawn from a multivariate normal distribution and examination of the continuous variables indicated this was not the case. Judged by the Shapiro-Wilkes test, not one of the variables was found to be univariate normal, and this is a requirement for multivariate normality.

However, because this restriction had not been considered in the Prediction class, it was decided to run these models any way. The results were surprising.

### Out of sample accuracy:
LDA:    ~74%

QDA:    ~92%
 
These results were both significantly higher than the accuracy observed for the decision tree model. An attempt to combine these two models yielded a final model with a lower accuracy rate of 45%

## Details for the final QDA model
The clear winner in the search for an optimal prediction model for predicting 'classe' of activity from accelerometer data was the quadratic discriminate model. The results are shown below:

```{R,echo=FALSE}
modqda = train(classe~., data=training, method="qda")

## Prediction
pqda = predict(modqda, testing)

## Printing out a confusion matrix with statistics
confusionMatrix(pqda, testing$classe)
```

